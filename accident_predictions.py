# -*- coding: utf-8 -*-
"""Accident Predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fL4WN7wfNRIlQQKwc3Z0OkpX_H-aLYH7
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_absolute_error
from pmdarima.arima import auto_arima
import os
import logging

# Initialize logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Step 1: Load the dataset
file_path = input("Enter the full file path (e.g., 'C:/Users/monik/OneDrive/Desktop/demo.csv'): ")
if not os.path.exists(file_path):
    raise FileNotFoundError(f"The dataset file '{file_path}' could not be found. Please check the file path.")
    
try:
    df = pd.read_csv(file_path)
    logging.info("Dataset loaded successfully.")
except FileNotFoundError:
    raise FileNotFoundError(f"The dataset file '{file_path}' could not be found. Please check the file path.")

# Step 2: Rename columns for clarity
df.rename(columns={
    'MONATSZAHL': 'Category',
    'AUSPRAEGUNG': 'Accident_type',
    'JAHR': 'Year',
    'MONAT': 'Month',
    'WERT': 'Value'
}, inplace=True)

# Step 3: Filter relevant columns
initial_row_count = len(df)
df = df[['Category', 'Accident_type', 'Year', 'Month', 'Value']]

# Step 4: Filter for Year >= 2020
df = df[df['Year'] <= 2020]
assert df['Year'].max() <= 2020, "Records beyond 2020 found in dataset."

# Step 5: Filter for specific Category and Accident_type
df = df[(df['Category'] == 'Alkoholunfälle') & (df['Accident_type'] == 'insgesamt')]

# Step 6: Handle the Month column
df['Month'] = df['Month'].astype(str).str[-2:].str.zfill(2)
valid_months = [str(i).zfill(2) for i in range(1, 13)]
df = df[df['Month'].isin(valid_months)]

# Log dropped rows
logging.info(f"Rows dropped after filtering: {initial_row_count - len(df)}")

# Step 7: Handle missing values in 'Value'
df['Value'] = df['Value'].interpolate(method='linear')
logging.info("Missing values handled using linear interpolation.")

# Step 8: Create a date index
df['Date'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'] + '-01', format='%Y-%m-%d')
df.set_index('Date', inplace=True)
df = df[['Value']]

# Ensure the DataFrame has a valid time series structure
df = df.asfreq('MS')

# Log if DataFrame is empty
if df.empty:
    raise ValueError("No data available after processing. Please check the dataset.")

# Step 9: Plot historical data
plt.figure(figsize=(12, 6))
plt.plot(df, label='Historical Data')
plt.title('Monthly Accidents for Alkoholunfälle (insgesamt)')
plt.xlabel('Date')
plt.ylabel('Number of Accidents')
plt.legend()
plt.grid()
plt.show()

# Step 10: Train-Test Split
# Create the test DataFrame for January 2021
train = df[:'2020']
test = pd.DataFrame(index=pd.date_range('2021-01-01', '2021-01-01', freq='MS'))
test['Value'] = np.nan

# Validate that the test DataFrame and forecast are aligned

if train.empty:
    raise ValueError("The train dataset is empty after filtering or dropping missing values.")

# Step 11: ARIMA Model Selection using Auto-ARIMA
train = df[:'2020']
try:
    auto_model = auto_arima(
        train['Value'],
        seasonal=False,
        stepwise=True,
        suppress_warnings=True,
        error_action='ignore',
        max_order=10,
        trace=True
    )
    order = auto_model.order
    logging.info(f"Selected ARIMA Order: {order}")
except Exception as e:
    raise ValueError(f"Auto-ARIMA model selection failed: {e}")

try:
    model = ARIMA(train['Value'], order=order)
    fitted_model = model.fit()
except Exception as e:
    raise ValueError(f"ARIMA model training failed: {e}")


# Step 12: Train ARIMA Model
model = ARIMA(train['Value'], order=order)
fitted_model = model.fit()

# Step 13: Forecast
forecast = fitted_model.forecast(steps=len(test))
logging.info(f"Forecast for Jan 2021: {forecast[0]}")

# Validate forecast alignment
if test.empty or len(test.index) != len(forecast):
    raise ValueError("Test DataFrame and forecast dimensions do not match.")

    # Calculate Mean Absolute Error if test data exists and does not contain NaN
if not test.empty and not test['Value'].isnull().all():
    # Ensure test['Value'] and forecast are aligned and NaN-free
    actual_values = test['Value'].dropna()
    mae = mean_absolute_error(actual_values, forecast[:len(actual_values)])
    logging.info(f"Mean Absolute Error (MAE): {mae}")
else:
    logging.warning("Test data contains only NaN values. Cannot calculate MAE.")


# Plotting
plt.figure(figsize=(12, 6))
plt.plot(train, label='Training Data')  # Historical training data
plt.plot(test.index, test['Value'], label='Test Data', marker='o', color='blue')  # Placeholder for actual test data
plt.plot(test.index[:len(forecast)], forecast, label='Forecast (Jan 2021)', marker='o', color='red') # Forecasted data
plt.title('Forecasting Monthly Accidents')
plt.xlabel('Date')
plt.ylabel('Number of Accidents')
plt.legend()
plt.grid()
plt.show()

# Step 15: Save Forecast Results
output_dir = './results'
os.makedirs(output_dir, exist_ok=True)
output_file = os.path.join(output_dir, 'forecast_results.csv')
forecast_df = pd.DataFrame({'Date': test.index, 'Prediction': forecast})
forecast_df.to_csv(output_file, index=False)
logging.info(f"Forecast saved to '{output_file}'")